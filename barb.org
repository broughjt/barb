#+title: Barb
#+date: <2023-12-25 Mon>
#+author: Jackson Brough

* Introduction

With minimal exceptions so far, I have written the proofs without
looking at anybody else's code first. I will try to explicitly state
where this isn't the case. For example, in Tao's Analyis 1 book, I
will look at the theorem statement and then try to prove it myself
before looking at the proof below. Obviously once I get past basic
arithmetic this ideal won't last very long -- I'll have to look at
other proofs to even get an idea of how to approach the
problem. However, my goal is to get as much insight from this project
as possible, so I'll have to find a working balance.

* Library
Right now, this project is a formalization of Terence Tao's Analyis I
[cite:@tao2022analysis]. My hope is to continue to other books, but
for now it pretty much directly follows the structure of Tao's book.

While the library is small, I'm going to group things here into a
collection of utilities and then the files for the natural numbers,
integers, rationals, and reals, respectively. This won't correspond
directly to the actual file structure, but I think that's actually a
good thing. If I'm going to maintain some sort of literature component
to this library, I would like it to tell a story about my learning
path, and that will have a very different structure than the code
dependencies between modules.

#+begin_src lean4 :tangle Barb.lean
import «Barb».Algebra
import «Barb».Function
import «Barb».Logic
import «Barb».Order
import «Barb».Quotient
import «Barb».Syntax

import «Barb».Data.Natural
import «Barb».Data.Integer
import «Barb».Data.Rational

import «Barb».Data.Option
#+end_src

** Natural
:PROPERTIES:
:header-args: :tangle Barb/Data/Natural.lean
:END:

"The positive integers and their arithmetic are presupposed by the
very nature of our intelligence and, we are tempted to believe, by the
very nature of intelligence in general. The development of the
positive integers from the primitive concept of the unit, the concept
of adjoining a unit, and the process of mathematical induction carries
complete conviction. In the words of Kronecker, the positive integers
were created by God."

"Kronecker forgot to mention how shoddy the work of man can be."

TODO: Cite

In this module, we construct the natural numbers and develop their
basic algebraic and order theoretic properties.

#+begin_src lean4
import Barb.Function
import Barb.Logic
import Barb.Order
#+end_src

The proofs that follow were my first real exposure to proving things
in Lean. I had worked with Coq tactic proofs before, but I wanted to
understand term-style proofs in Lean instead of just playing Whac-A-Mole
with tactics I didn't understand yet. People talk about how using an
interactive theorem prover can feel like playing a video game: you
look at the current state, you look at the goal state after the
turnstile, and you make moves that get you closer to the goal until
the red squigglies go away. I wanted to use tactics only after I
understood what kind of terms they were generating. Further, a
general goal for this project is to understand the proofs I write. I
should always be able to give a convincing paper proof of any theorem
in here. Unfortunately, there are already exceptions to this, as you
have seen with the two other Peano axioms.

I think starting with pure term-style proofs was very worth it. I
learned how inductive proofs match up with the recursor, and where
before, proofs of equality or negation were totally magic to me in
Coq, they make intuitive sense to me now. After I had done a dozen or
so of these, I read the [[https://leanprover.github.io/theorem_proving_in_lean4/tactics.html][tactics chapter]] in Theorem Proving in Lean 4
and started revising the proofs to use tactics.

What I'll do for the following theorems is provide some explanation,
then show my original term-style proof if it exists (cleaned up a bit
to match how I learned to do things later), and then finally show my
revised tactic-style proof which will be the one that actually gets
tangled. Even so, while writing the natural numbers module I was still
opposed to using much of the rewriter or the simplifier because I
didn't understand how they worked. You'll see me use those tactics
freely in the development of the integers and the rationals, but I
think it's kind of nice to make the proofs here as explicit as
possible. (Psych, there are quite a few theorems in here now which use
~rw~ and ~simp~.)

TODO: Why? Is here a good place to explain the developmental nature of
the writing?

*** Definition and Peano axioms

The inductive definition of the natural numbers starts with an
assumption that we have a zero element in $\mathbb{N}$ -- and yes, the natural
numbers start at zero: people who think the natural numbers start at
one have no class. Then we assume that for any $n$ in $\mathbb{N}$,
the successor $S(n)$ of $n$ is also in $\mathbb{N}$. In type theory,
just like literally everything else, we can represent this structure with an
inductive type.

#+begin_src lean4
inductive Natural where
  | zero : Natural
  | successor : Natural → Natural
#+end_src

This inductive type declaration adds two constructors, ~zero~ and
~successor~, and an eliminator, which is a principle of recursion
and as a special case a principle of induction. These three
correspond to axioms 2.1, 2.2, and 2.5
[cite:@tao2022analysis, p.16-18]. What's cool is that the remaining
Peano axioms are Peano theorems in our construction. This falls out of the
interesting properties of inductive type constructors in type theory,
which I don't fully understand yet.

First, we define conversions between our ~Natural~ type and the built
in ~Nat~ to be able to write $3 : \mathbb{N}$ instead of
~successor(successor(successor(zero))) : Natural~.

#+begin_src lean4
namespace Natural

open Natural (zero successor)

def fromNat : Nat → Natural
  | Nat.zero => Natural.zero
  | Nat.succ n => Natural.successor (fromNat n)

def toNat : Natural → Nat
  | Natural.zero => Nat.zero
  | Natural.successor n => Nat.succ (toNat n)

instance : OfNat Natural n where
  ofNat := fromNat n

instance : ToString Natural where
  toString := toString ∘ toNat

notation "ℕ" => Natural
#+end_src

Tao includes two other Peano axioms. Axiom 2.3 states that zero is not the successor of any natural number,
and axiom 2.4 states that the successor operation is injective, that
is, if $S(n) = S(m)$ then $n = m$.

I went on a long journey trying to understand ~noConfusion~, where I
read [[https://xenaproject.wordpress.com/2018/03/24/no-confusion-over-no_confusion/][No confusion over no_confusion]] and attempted to write my own
version. Unfortunately I'm still mostly confused. I think at one point
I slightly grasped it, but all of that is gone now. I especially don't
understand why the $id$ nonsense works in ~successor_injective~ -- I
just threw terms around until they type checked.

#+begin_src lean4
theorem successor_not_equal_zero (n : ℕ) : successor n ≠ 0 :=
  Natural.noConfusion

theorem successor_injective : Function.Injective successor :=
  λ h => (Natural.noConfusion h) id
#+end_src

Now we prove that the successor of a number is never equal to that
number. The proof works by applying the injectivity of the successor
in the inductive step, forming a long chain of deductive steps stemming
from the fact that zero is not the successor of any element of $\mathbb{N}$.

#+begin_src lean4 :tangle no
theorem successor_not_equal_self' (n : ℕ) : successor n ≠ n :=
  Natural.rec 
    (successor_not_equal_zero 0) 
    (λ _ ih => λ h => ih (successor_injective h))
    n
#+end_src

#+begin_src lean4
theorem successor_not_equal_self (n : ℕ) : successor n ≠ n := by
  induction n with
  | zero => exact successor_not_equal_zero 0
  | successor n ih => intro h; exact ih (successor_injective h)
#+end_src

*** Addition

Addition is defined to be repeated application of the successor. To
add four to five is the same as incrementing five four times. We can
give a recursive definition as follows.

#+begin_src lean4
def add : ℕ → ℕ → ℕ
  | zero, m => m
  | successor n, m => successor (add n m)

instance : Add Natural where
  add := add

@[simp] theorem add_definition : add n m = n + m := rfl
#+end_src

I'm definitely a recurse-on-the-left kind of guy, but we could have
recursed on the right. Now in type theory, this decision actually
bears some consequences due to the distinction between definitional
equality and um... other kinds of equality. That's a whole can of
worms; the type theorists are (rightly) very particular about the
different notions of equality. That's all I say for now, 
because I don't think I do the concepts justice at my current level of
understanding.

In our case, the equations $0 + n = n$ and $S(n) + m = S(n + m)$ hold
definitionally, but $n + 0 = n$ and $n + S(m) = S(n + m)$ require
proof. Luckily we can prove these statements with induction, and then
show that addition is commutative, which will make our choice of
definition less of a big deal.

#+begin_src lean4
theorem zero_add (n : ℕ) : 0 + n = n := rfl

theorem successor_add (n m : ℕ) : (successor n) + m = successor (n + m) := rfl
#+end_src

The proof that $n + 0 = n$ works by rewriting $S(n) + 0$ to $S(n + 0)$
using the definition and then applying the inductive hypothesis, which
claims that $n + 0 = n$ for an arbitary $n : \mathbb{N}$. This is
easier to see in the tactic-style proof.

#+begin_src lean4 :tangle no
theorem add_zero' (n : ℕ) : n + 0 = n := 
  Natural.rec
    (zero_add 0)
    (λ (x : ℕ) (ih : x + 0 = x) =>
      have h1 : (successor x) + 0 = successor (x + 0) := successor_add x 0
      have h2 : successor (x + 0) = (successor x) + 0 := Eq.symm h1
      have h3 : successor x = (successor x) + 0 := 
        Eq.subst (motive := λ a => successor a = (successor x) + 0)
          ih
          h2
      show (successor x) + 0 = successor x from Eq.symm h3)
    n
#+end_src

#+begin_src lean4
@[simp] theorem add_zero (n : ℕ) : n + 0 = n := by
  induction n with
  | zero => exact zero_add 0
  | successor n ih => calc
    (successor n) + 0 = successor (n + 0) := successor_add n 0
    _                 = successor n       := congrArg successor ih
#+end_src


When I wrote the term-style proof, I didn't know about ~congrArg~ and
so I had to hack together equality substitutions, which is what
~congrArg~ generalizes. I also used the ~have~ and ~show~ keywords,
since they are just nice ways of writing ~let~ and explicitly
declaring the type of an expression, respectively, and this didn't
feel like any big jump from pure lambda terms.

The tactic style proof is much cleaner. While writing the naturals, I
really got into the calc-mode style of lining up transitive relations
step-wise.

The next proof is very similar to the last theorem: we do two
rewrites using the definition of addition and the inductive hypothesis
and we're done. I discovered ~congrArg~ while writing the term-style
proof for this one. It's awesome; it saves you from having to
prove the same throw-away mini lemmas over and over.

#+begin_src lean4 :tangle no
theorem add_successor' (n m : ℕ) : n + (successor m) = successor (n + m) :=
  Natural.rec
    (
      have h1 : 0 + (successor m) = successor m := zero_add (successor m)
      -- congrArg to the rescue!
      have h2 : successor (0 + m) = successor m := congrArg successor (zero_add m)
      show 0 + (successor m) = successor (0 + m) from Eq.trans h1 (Eq.symm h2)
    )
    (λ (x : ℕ) (ih : x + (successor m) = successor (x + m)) =>
      have h1 : (successor x) + (successor m) = successor (x + (successor m)) := successor_add x (successor m)
      have h2 : successor (x + (successor m)) = successor (successor (x + m)) := congrArg successor ih
      -- Little extra help from the compiler since (successor x) + m) is definitionally equal to sucessor (x + m)
      show (successor x) + (successor m) = successor ((successor x) + m) from Eq.trans h1 h2
    )
    n
#+end_src

#+begin_src lean4
theorem add_successor (n m : ℕ) : n + (successor m) = successor (n + m) := by
  induction n with
  | zero => calc
    0 + (successor m) = successor m       := zero_add (successor m)
    _                 = successor (0 + m) := congrArg successor (zero_add m)
  | successor n ih => calc
    (successor n) + (successor m) = successor (n + (successor m)) := successor_add n (successor m)
    _                             = successor (successor (n + m)) := congrArg successor ih
#+end_src

Now we develop the commutativity, associativity, and cancellation laws
for addition.

Why is addition commutative? Incrementing $n$ 5 times always gives the same
result as incrementing 5 $n$ times. This bears itself it out in the
proof: we make direct use of the two theorems we just proved. I had
term-style proofs of all of these, but I will spare you.

#+begin_src lean4
theorem add_commutative (n m : ℕ) : n + m = m + n := by
  induction n with
  | zero => calc
    0 + m = m     := zero_add m
    _     = m + 0 := (add_zero m).symm
  | successor n ih => calc
    (successor n) + m = successor (n + m) := successor_add n m
    _                 = successor (m + n) := congrArg successor ih
    _                 = m + (successor n) := (add_successor m n).symm
#+end_src

It's a bit harder to come with an intuitive explanation for
associativity. The order just doesn't matter man, that's all I have
for you. The proof's nice though, you just move the successor to the
front using the theorems we developed for right-hand side successor
addition and then you rewrite inside the successor using the inductive
hypothesis.

#+begin_src lean4
theorem add_associative (n m k : ℕ) : (n + m) + k = n + (m + k) := by
  induction n with
  | zero => calc
    (0 + m) + k = m + k       := congrArg (. + k) (zero_add m)
    _           = 0 + (m + k) := zero_add (m + k)
  | successor n ih => calc
    ((successor n) + m) + k = (successor (n + m)) + k := congrArg (. + k) (successor_add n m)
    _                       = successor ((n + m) + k) := successor_add (n + m) k
    _                       = successor (n + (m + k)) := congrArg successor ih
#+end_src

These lemmas end up being useful in the future when you're rewriting
heavily nested expressions, but they really should just not exist; if
only the simplifier was better.

#+begin_src lean4
theorem add_left_commutative (n m k : ℕ) : n + (m + k) = m + (n + k) := by
  rw [← add_associative, add_commutative n m, add_associative]
  
theorem add_right_commutative (n m k : ℕ) : (n + m) + k = (n + k) + m := by
  rw [add_associative, add_commutative m k, ← add_associative]
#+end_src

Addition is left cancellative because, well, if $n + m$ and
$n + k$ are the same value, then $m$ had better equal $k$ -- that's
why. The real proof is inductive and utilizes the fact that zero is an
additive identity and that the successor is injective.

#+begin_src lean4
theorem add_left_cancel {n m k : ℕ} : n + m = n + k → m = k := by
  induction n with
  | zero => 
    intro h
    calc
      m = 0 + m := zero_add m
      _ = 0 + k := h
      _ = k     := zero_add k
  | successor n ih =>
    intro h
    have := calc
      successor (n + m) = (successor n) + m := (successor_add n m).symm
      _                 = (successor n) + k := h
      _                 = successor (n + k) := successor_add n k
    exact ih (successor_injective this)

theorem add_right_cancel {n m k : ℕ} (h : n + k = m + k) : n = m := by
  rw [add_commutative n k, add_commutative m k] at h
  exact add_left_cancel h
#+end_src

*** Decidable equality

The law of the excluded middle essentially claims that every
proposition is decidable, that is, that $p \lor \neg p$ holds for any
proposition $p$. Once you're cool to give this up, there is this really cool
distinction between decidable and non-decidable propositions. Even
though it doesn't hold in the general case, you can show that certain
classes of propositions /are/ decidable.

You accomplish this by giving a _decision procedure_ which shows how
to "decide" a predicate -- and mind you, a predicate is a function
which sends values to propositions, or a value-indexed family of
propositions. It is /not/ a function which returns a
boolean. Identifying statements with elements of $\{\top, \bot\}$ is
something from classical logic that feels super weird to me.

A little more formally, a decision procedure takes a predicate of the
form ~p : α → Prop~ and an element of that type ~a : α~, and _decides_
~p a~ by providing a proof of ~p a~ or a proof ~¬(p a)~. Giving a
decision procedure for a predicate ~p~ shows that ~p~ is _decidable_,
because given any instance ~a : α~, we have an algorithm for showing
whether ~p a~ or not ~p a~.

This section has gone through several different iterations, but the
latest version includes a small grouping of lemmas about the
~distance~ function for natural numbers, which basically gives the
absolute value difference between the two values, except that we don't
compute it using subtraction, because we tried that earlier and
natural number subtraction is super broken hack.

You'll notice that I'm totally willing to use the ~rw~ and ~simp~
tactics here. This might feel anachronistic, since I avoid them
everywhere else in the natural number proofs, and that's because it is:
I came from the future because I needed these theorems for the integers.

#+begin_src lean4
@[simp]
def distance : ℕ → ℕ → ℕ
  | zero, zero => 0
  | successor n, zero => successor n
  | zero, successor m => successor m
  | successor n, successor m => distance n m

theorem equal_of_distance_equal_zero : ∀ {n m : ℕ}, distance n m = 0 → n = m
  | zero, zero, _ => rfl
  | successor n, successor m, h => by
    unfold distance at h
    exact congrArg successor (equal_of_distance_equal_zero h)

theorem distance_equal_zero_of_equal : ∀ {n m : ℕ}, n = m → distance n m = 0
  | zero, zero, _ => rfl
  | successor n, successor m, h => by
    unfold distance
    exact distance_equal_zero_of_equal (successor_injective h)

theorem distance_self : ∀ (n : ℕ), distance n n = 0 :=
  λ _ => distance_equal_zero_of_equal rfl

theorem distance_zero_left : ∀ (n : ℕ), distance n 0 = n
  | zero => rfl
  | successor n => by unfold distance; rfl

theorem distance_commutative : ∀ (n m : ℕ), distance n m = distance m n
  | zero, zero => distance_zero_left _
  | zero, successor _ => distance_zero_left (successor _)
  | successor _, zero => distance_zero_left (successor _)
  | successor _, successor _ => by
    simp
    apply distance_commutative

theorem distance_zero_right (n : ℕ) : distance 0 n = n := by
  rw [distance_commutative, distance_zero_left]

theorem distance_add_add_right (n m k : ℕ) : distance (n + k) (m + k) = distance n m := by
  induction k with
  | zero =>
    have this : zero = 0 := rfl
    simp [this, add_zero]
  | successor k ih =>
    simp [add_successor]
    exact ih

theorem distance_add_add_left (n m k : ℕ) : distance (n + m) (n + k) = distance m k := by
  rw [add_commutative n m, add_commutative n k, distance_add_add_right]
#+end_src

I still can't figure out what to call this next theorem. It states
that if two sums are equal, the distance between the first terms of
each sum must be made up for exactly in the distance between the
second terms. Writing this out visually is also compelling. Arrange
two equal length lines cut into two different length segments, name
the segments $n$, $m$, $k$, and $l$, and then arrange a copy of each
segment vertically so that their left ends line up. It will become
apparent that the difference in lengths between $n$ and $k$ match up
with the difference between $l$ and $m$.

#+begin_src lean4
theorem distance_equal_of_add_equal {n m k l : ℕ} (h : n + m = k + l) : distance n k = distance l m := by
  calc
    distance n k = distance (n + m) (k + m) := (distance_add_add_right n k m).symm
    _ = distance (k + l) (k + m) := congrArg (λ x => distance x _) h
    _ = distance l m := distance_add_add_left k l m
#+end_src

Since we have shown that $\mathnormal{distance}(n, m) = 0$ and $n = m$
are logically equivalent, we can use the distance function to decide
equality. This will be a common theme: when we develop decision
procedures for equality or other relations, we often establish a
logical equivalence between something we know how to compute and the
proposition we want to decide. The connection between decidable
propositions, computability, and computational complexity seems to be
very important, and I'm interested to go deeper on this idea.

#+begin_src lean4
instance decideEqual : DecidableEq Natural
  | n, m => match h : distance n m with
    | zero => isTrue (equal_of_distance_equal_zero h)
    | successor a => isFalse (mt distance_equal_zero_of_equal (h ▸ successor_not_equal_zero a))
#+end_src

Corollary 2.2.9 [cite:@tao2022analysis, p. 26] utilizes proof by
contradiction. Corollaries are supposed to follow easily from a
previously stated theorem, but without being able to prove it with
contradiction, the proof of ~equal_zero_of_add_equal_zero~ was way,
way more involved then ~add_positive~, which it was supposed to follow
from. Now that we have decidability, we can employ our classical proof
methods locally. Specifically, we use double negation here, which in
this case says that that $\neg \neg n = m \to n = m$.

#+begin_src lean4
theorem add_positive {n m : ℕ} : n ≠ 0 → (n + m) ≠ 0 :=
  match n with
  | zero => absurd rfl
  | successor n => λ _ => successor_not_equal_zero (n + m)

theorem equal_zero_of_add_equal_zero {n m : ℕ} (h : n + m = 0) : n = 0 ∧ m = 0 := by
  apply And.intro
  . exact Decidable.of_not_not (mt add_positive (not_not_intro h))
  . have : m + n = 0 := (add_commutative n m).symm.trans h
    exact Decidable.of_not_not (mt add_positive (not_not_intro this))

theorem unique_predecessor_of_positive {n : ℕ} : n ≠ 0 → ∃! (m : ℕ), successor m = n :=
  match n with
  | zero => absurd rfl
  | successor n => λ _ => ExistsUnique.introduction n rfl (λ _ => successor_injective)
#+end_src

*** Order

Remember when I said that people with class start the natural numbers
out at zero? Well now we get to reap the benefits of our correct decision
making. Let $n$ and $m$ be natural numbers. We say the $n$ is less
than or equal to $m$ if there exists a natural number $a$ for which
$n + a = m$. We say that $n$ is strictly less than $m$ when $a$ is
positive, that is, when it is nonzero (we don't have negative numbers
yet).

#+begin_src lean4
def LessEqual (n m : ℕ) : Prop := ∃ (a : ℕ), n + a = m

instance : LE Natural where
  le := LessEqual

@[simp] theorem less_equal_definition : (LessEqual n m) = (n ≤ m) := rfl
#+end_src

In my opinion, making less than or equal the more primitive
notion makes the proofs cleaner, and at any rate, this is how Tao
defines things too (until the rationals where he switches things up on
you out of nowhere -- what's that about).

Now we show that the less than or equal relation forms a total order on the
natural numbers, and we give a decision procedure for less than or equal as
well. A total order requires that a relation be reflexive,
antisymmetric, transitive, and strongly connected, which altogether
basically allows us to stick any two natural numbers on a line and
compare their relative positions. TODO this is bad informal
explanation.

First, the less equal relation is reflexive, that is, we have $n \le n$ for
any $n : \mathbb{N}$, because zero is an additive identity.

#+begin_src lean4
@[simp] theorem LessEqual.reflexive : Relation.Reflexive LessEqual :=
  λ n => Exists.intro 0 (add_zero n)
#+end_src

Being antisymmetric means that there are no two distinct elements which are
related to each other in both directions, which we state logically as
$n \le m \to m \le n \to n = m$ for all $n, m : \mathbb{N}$. To show this, we prove
$n + (a + b) = n + 0$ must hold by substituting in both hypotheses,
which implies $a + b = 0$. For natural numbers, this means $a$ and
$b$ must both be zero, and therefore $n = m$.

#+begin_src lean4
theorem LessEqual.antisymmetric : Relation.AntiSymmetric LessEqual := by
  intro n m ⟨a, (ha : n + a = m)⟩ ⟨b, (hb : m + b = n)⟩
  suffices a + b = 0 by 
  { have ⟨a_zero, _⟩ := equal_zero_of_add_equal_zero this
    rw [← add_zero n, ← a_zero, ha] }
  apply add_left_cancel (n := n)
  rw [← add_associative, ha, hb, add_zero]
#+end_src

To show that the less equal relation is transitive, just substitute
the equation for the first definition into the equation for the
second. Nice.

#+begin_src lean4
theorem LessEqual.transitive : Relation.Transitive LessEqual := by
  intro n m k ⟨a, (ha : n + a = m)⟩ ⟨b, (hb : m + b = k)⟩
  apply Exists.intro (a + b)
  rw [← add_associative, ha, hb]
#+end_src

Now we have shown that less equal is a partial order, but before we
show strong connectedness, we will develop a decision procedure for
less equal, because I couldn't come up with a nice proof for strong
connectedness without just deferring to decidability in a double
induction argument. You'll see what I mean. To make a decision
procedure, we need a few lemmas first.

#+begin_src lean4
@[simp] theorem zero_less_equal (n : ℕ) : 0 ≤ n := 
  Exists.intro n (zero_add n)
  
theorem equal_zero_of_less_equal_zero : ∀ {n : ℕ}, n ≤ 0 → n = 0 := by
  intro n ⟨a, (h: n + a = 0)⟩
  have := equal_zero_of_add_equal_zero h
  exact this.left
  
theorem less_equal_of_successor_less_equal_successor {n m : ℕ} : successor n ≤ successor m → n ≤ m := by
  intro ⟨a, (h : successor n + a = successor m)⟩
  apply Exists.intro a
  apply successor_injective
  rw [← successor_add, h]
  
theorem successor_less_equal_successor_of_less_equal {n m : ℕ} : n ≤ m → successor n ≤ successor m := by
  intro ⟨a, (h : n + a = m)⟩
  have := calc
    successor n + a = successor (n + a) := successor_add _ _
    _ = successor m := congrArg successor h
  exact Exists.intro a this
  
theorem less_equal_successor_of_less_equal {n m : ℕ} : n ≤ m → n ≤ successor m := by
  intro ⟨a, (h : n + a = m)⟩
  have := calc
    n + successor a = successor (n + a) := add_successor _ _
    _ = successor m := congrArg successor h
  exact Exists.intro (successor a) this
#+end_src

We also need a boolean less equal function. The two lemmas following
that show that the output of this function is logically consistent
with the propositional version.

#+begin_src lean4
def booleanLessEqual : ℕ → ℕ → Bool
  | zero, zero => true
  | zero, successor _ => true
  | successor _, zero => false
  | successor n, successor m => booleanLessEqual n m

theorem less_equal_of_boolean_less_equal_true {n m : ℕ} (h : (booleanLessEqual n m) = true) : n ≤ m :=
  match n, m with
  | zero, _ => zero_less_equal _
  | successor _, successor _ => successor_less_equal_successor_of_less_equal (less_equal_of_boolean_less_equal_true h)
  
theorem boolean_less_equal_true_of_less_equal : ∀ {n m : ℕ}, n ≤ m → (booleanLessEqual n m) = true
  | zero, m, _ => by cases m <;> rfl
  | successor n, successor m, h => by
    rw [booleanLessEqual]
    have := less_equal_of_successor_less_equal_successor h
    exact boolean_less_equal_true_of_less_equal this
#+end_src

Now the decision procedure is easy: run the function and apply the
lemmas we proved to show that this function suffices to decide the proposition
in both cases.

#+begin_src lean4
instance decideLessEqual (n m : ℕ) : Decidable (n ≤ m) :=
  if h : (booleanLessEqual n m) = true then
    isTrue (less_equal_of_boolean_less_equal_true h)
  else
    isFalse (mt boolean_less_equal_true_of_less_equal h)
#+end_src

Now we can use decidability to show strong connectedness, which tells
us that any two elements are comparable. I don't have any better
justification for this fact other than that it holds if one of the
elements is zero, and that this holds inductively because we proved
$n \le m$ implies $S(n) \le S(m)$.

#+begin_src lean4
theorem LessEqual.strongly_connected : Relation.StronglyConnected LessEqual
  | zero, _ => Or.inl (zero_less_equal _)
  | successor _, zero => Or.inr (zero_less_equal _)
  | successor n, successor m =>
    Or.implies 
      successor_less_equal_successor_of_less_equal 
      successor_less_equal_successor_of_less_equal 
      (LessEqual.strongly_connected n m)
#+end_src

Together these properties show that less equal forms a total order for
the natural numbers.

#+begin_src lean4
instance totalOrder : DecidableTotalOrder Natural where
  less_equal_reflexive := LessEqual.reflexive
  less_equal_antisymmetric := LessEqual.antisymmetric
  less_equal_transitive := LessEqual.transitive
  less_equal_strongly_connected := LessEqual.strongly_connected
  decideEqual := decideEqual
  decideLessEqual := decideLessEqual
#+end_src

Because order theory is awesome, every total order induces a strict
total order, so we get the less than relation for free. It is defined
by $n \le m \land \neg (m \le n)$. See the order theory module for the
interesting details.

#+begin_src lean4
def LessThan : ℕ → ℕ → Prop := strictPartialOrderOfPreorder.lt
#+end_src

The rest of this stuff is a hodge podge of very trivial statements about
order. The important ones are

- ~add_left_less_equal~:
  $\forall n, m, k : \mathbb{N}, m \le k \to n + m \le n + k$
- ~less_equal_of_add_left_less_equal~:
  $\forall n, m, k : \mathbb{N}, n + m \le n + k \to m \le k$
- ~equal_add_positive_of_less_than~:
  $\forall n, m : \mathbb{N}, n < m \to (\exists a : \mathbb{N}, a \ne
  0 \land n + a = m)$
- ~less_than_of_equal_add_positive~:
  $\forall n, m, a : \mathbb{N}, a \ne 0 \land n + a = m \to n < m$

There are also ~less_than~ versions for the first two.

#+begin_src lean4
theorem less_than_successor (n : ℕ) : n < successor n :=
  have := less_than_or_equal_of_less_equal (less_equal_successor_of_less_equal (less_equal_reflexive n))
  Or.resolve_right this (successor_not_equal_self n).symm

theorem less_than_of_successor_less_equal {n m : ℕ} (h : successor n ≤ m) : n < m :=
  less_than_of_less_than_of_less_equal (less_than_successor n) h

theorem less_than_successor_of_less_equal {n m : ℕ} (h : n ≤ m) : n < successor m := 
  less_than_of_less_equal_of_less_than h (less_than_successor m)

theorem successor_less_equal_of_less_than {n m : ℕ} (h : n < m) : successor n ≤ m :=
  have ⟨a, (ha : n + a = m)⟩ := less_equal_of_less_than h
  have hnm := not_equal_of_less_than h
  match a with
  | zero => absurd ((add_zero _).symm.trans ha) hnm
  | successor a => 
    have := calc
      successor n + a = successor (n + a) := successor_add _ _
      _ = n + successor a := (add_successor _ _).symm
      _ = m := ha
    Exists.intro a this

theorem less_equal_of_successor_less_equal {n m : ℕ} : successor n ≤ m → n ≤ m := 
  less_equal_of_less_than ∘ less_than_of_successor_less_equal
    
theorem less_than_of_successor_less_than_successor {n m : ℕ} : successor n < successor m → n < m :=
  less_than_of_successor_less_equal ∘ less_equal_of_successor_less_equal_successor ∘ successor_less_equal_of_less_than

theorem equal_zero_or_positive (n : ℕ) : n = 0 ∨ n > 0 :=
  Or.implies_left 
  Eq.symm
  (Or.commutative.mp (less_than_or_equal_of_less_equal (zero_less_equal n)))

theorem not_successor_less_equal_zero (n : ℕ) : ¬(successor n ≤ 0) := by
  intro ⟨a, (ha : successor n + a = 0)⟩
  rw [successor_add] at ha
  exact (successor_not_equal_zero _) ha

theorem zero_less_than_successor (n : ℕ) : successor n > 0 :=
  Or.resolve_left (equal_zero_or_positive (successor n)) (successor_not_equal_zero _)

theorem not_less_than_zero (n : ℕ) : ¬(n < 0) :=
  λ h => not_successor_less_equal_zero n (successor_less_equal_of_less_than h)

theorem zero_less_than_positive {n : ℕ} : n ≠ 0 → 0 < n :=
  Or.resolve_left (equal_zero_or_positive n)
  
theorem nonzero_of_less_than {n m : ℕ} (h : n < m) : m ≠ 0 :=
  match m with
  | zero => absurd h (not_less_than_zero _)
  | successor _ => successor_not_equal_zero _

theorem add_left_less_equal {m k : ℕ} (h : m ≤ k) (n : ℕ) : n + m ≤ n + k :=
  let ⟨a, (h₁ : m + a = k)⟩ := h
  have := calc
    n + m + a = n + (m + a) := add_associative n m a
    _         = n + k       := congrArg (n + .) h₁
  Exists.intro a this

theorem add_right_less_equal {n m : ℕ} (h : n ≤ m) (k : ℕ) : n + k ≤ m + k := by
  rw [add_commutative n k, add_commutative m k]
  exact add_left_less_equal h k
    
theorem add_left_less_than {m k : ℕ} (h : m < k) (n : ℕ) : n + m < n + k := by
  have := add_left_less_equal (successor_less_equal_of_less_than h) n
  apply less_than_of_successor_less_equal
  calc
    successor (n + m) = n + successor m := (add_successor _ _).symm
    _ ≤ n + k := this

theorem add_right_less_than {n m : ℕ} (h : n < m) (k : ℕ) : n + k < m + k := by
  rw [add_commutative n k, add_commutative m k]
  exact add_left_less_than h k

theorem less_equal_of_add_left_less_equal {n m k : ℕ} (h : n + m ≤ n + k) : m ≤ k :=
  let ⟨a, (ha : (n + m) + a = n + k)⟩ := h
  have := calc
    n + (m + a) = (n + m) + a := (add_associative n m a).symm
    _           = n + k       := ha
  Exists.intro a (add_left_cancel this)

theorem less_equal_of_add_right_less_equal {n m k : ℕ} (h : n + k ≤ m + k) : n ≤ m := by
  rw [add_commutative n k, add_commutative m k] at h 
  exact less_equal_of_add_left_less_equal h
  
theorem less_than_of_add_left_less_than {n m k : ℕ} (h : n + m < n + k) : m < k :=
  have := calc
    n + successor m = successor (n + m) := add_successor _ _
    _ ≤ n + k := successor_less_equal_of_less_than h
  less_than_of_successor_less_equal (less_equal_of_add_left_less_equal this)

theorem less_than_of_add_right_less_than {n m k : ℕ} (h : n + k < m + k) : n < m := by
  rw [add_commutative n k, add_commutative m k] at h 
  exact less_than_of_add_left_less_than h

theorem equal_add_positive_of_less_than {n m : ℕ} (h : n < m) : 
  ∃ (a : ℕ), a ≠ 0 ∧ n + a = m := by
  let ⟨a, (ha : (successor n) + a = m)⟩ := successor_less_equal_of_less_than h
  apply Exists.intro (successor a)
  apply And.intro
  . exact successor_not_equal_zero a
  . calc
      n + (successor a) = successor (n + a) := add_successor _ _
      _                 = (successor n) + a := (successor_add _ _).symm
      _                 = m                 := ha

theorem less_than_of_equal_add_positive {n m a : ℕ} : a ≠ 0 → n + a = m → n < m := by
  intro a_not_zero ha
  let ⟨b, (hb : successor b = a), _⟩ := (unique_predecessor_of_positive a_not_zero)
  have := calc
    successor n + b = successor (n + b) := successor_add _ _
    _ = n + successor b := (add_successor _ _ ).symm
    _ = n + a := congrArg (_ + .) hb
    _ = m := ha
  exact less_than_of_successor_less_equal (Exists.intro b this)

theorem left_greater_equal_of_add_right_less_equal {n m k l : ℕ} : n + m = k + l → m ≤ l → n ≥ k := by
  intro h_equal ⟨a, (ha : m + a = l)⟩
  apply Exists.intro a
  apply add_left_cancel (n := m)
  rw [add_left_commutative, ha, ← h_equal, add_commutative]
  
theorem right_greater_equal_of_add_left_less_equal {n m k l : ℕ} : n + m = k + l → n ≤ k → m ≥ l := by
  intro h_equal h_less_equal
  rw [add_commutative n m, add_commutative k l] at h_equal
  exact left_greater_equal_of_add_right_less_equal h_equal h_less_equal
#+end_src

*** Multiplication

We define multiplication similarly to addition: just like addition was
iterated incrementation, multiplication is iterated addition.

#+begin_src lean4
def multiply : ℕ → ℕ → ℕ
  | zero, _ => 0
  | successor n, m => (multiply n m) + m

instance : Mul Natural where
  mul := multiply

@[simp] theorem multiply_definition : multiply n m = n * m := rfl
#+end_src

We show that multiplication satisfies the commutative, associative,
and left and right distributive properties.

#+begin_src lean4
@[simp] theorem zero_multiply (n : ℕ) : 0 * n = 0 := rfl

theorem successor_multiply (n m : ℕ) : (successor n) * m = (n * m) + m := rfl

@[simp] theorem multiply_zero (n : ℕ) : n * 0 = 0 := by
  induction n with
  | zero => rfl
  | successor n ih =>
    calc
      (successor n) * 0 = (n * 0) + 0 := successor_multiply n 0
      _                 = n * 0       := add_zero (n * 0)
      _                 = 0           := ih

theorem multiply_successor (n m : ℕ) : n * (successor m) = (n * m) + n := by
  induction n with
  | zero => rfl
  | successor n ih =>
    show (successor n) * (successor m) = ((successor n) * m) + (successor n)
    calc
      (successor n) * (successor m)
        = n * (successor m) + (successor m)   := successor_multiply n (successor m)
      _ = ((n * m) + n) + (successor m)       := congrArg (. + successor m) ih
      _ = (n * m) + (n + (successor m))       := add_associative (n * m) n (successor m)
      _ = (n * m) + successor (n + m)         := congrArg (n * m + .) (add_successor n m)
      _ = (n * m) + ((successor n) + m)       := congrArg (n * m + .) (successor_add n m).symm
      _ = (n * m) + (m + (successor n))       := congrArg (n * m + .) (add_commutative (successor n) m)
      _ = ((n * m) + m) + (successor n)       := (add_associative (n * m) m (successor n)).symm
      _ = ((successor n) * m) + (successor n) := congrArg (. + (successor n)) (successor_multiply n m).symm

theorem multiply_commutative (n m : ℕ) : n * m = m * n := by
  induction n with
  | zero =>
    calc
      0 * m = 0     := zero_multiply m
      _     = m * 0 := (multiply_zero m).symm
  | successor n ih =>
    calc
      (successor n) * m = (n * m) + m       := successor_multiply n m
      _                 = (m * n) + m       := congrArg (. + m) ih
      _                 = m * (successor n) := (multiply_successor m n).symm

theorem left_distributive (n m k : ℕ) : n * (m + k) = n * m + n * k := by
  induction k with
  | zero => calc
    n * (m + 0) = n * m         := congrArg (n * .) (add_zero m)
    _           = n * m + 0     := (add_zero (n * m)).symm
    _           = n * m + n * 0 := congrArg ((n * m) + .) (multiply_zero n).symm
  | successor k ih => calc
    n * (m + successor k)
      = n * successor (m + k)     := congrArg (n * .) (add_successor m k)
    _ = (n * (m + k)) + n         := multiply_successor n (m + k)
    _ = (n * m + n * k) + n       := congrArg (. + n) ih
    _ = n * m + (n * k + n)       := add_associative (n * m) (n * k) n
    _ = n * m + n * (successor k) := congrArg (n * m + .) (multiply_successor n k).symm

theorem right_distributive (n m k : ℕ) : (n + m) * k = n * k + m * k := by
  calc
    (n + m) * k = k * (n + m)   := multiply_commutative (n + m) k
    _           = k * n + k * m := left_distributive k n m
    _           = n * k + k * m := congrArg (. + k * m) (multiply_commutative k n)
    _           = n * k + m * k := congrArg (n * k + .) (multiply_commutative k m)

theorem multiply_associative (n m k : ℕ) : (n * m) * k = n * (m * k) := by
  induction n with
  | zero => calc
    (0 * m) * k = 0 * k       := congrArg (. * k) (zero_multiply m)
    _           = 0           := zero_multiply k
    _           = 0 * (m * k) := (zero_multiply (m * k)).symm
  | successor n ih => calc
    (successor n * m) * k
      = (n * m + m) * k       := congrArg (. * k) (successor_multiply n m)
    _ = ((n * m) * k) + m * k := right_distributive (n * m) m k
    _ = (n * (m * k)) + m * k := congrArg (. + m * k) ih
    _ = successor n * (m * k) := successor_multiply n (m * k)
#+end_src

Then for convience we give several lemmas which follow from these properties.

#+begin_src lean4
@[simp] theorem one_multiply (n : ℕ) : 1 * n = n := rfl

@[simp] theorem multiply_one (n : ℕ) : n * 1 = n := (multiply_commutative n 1).trans (one_multiply n)

theorem equal_zero_of_multiply_equal_zero {n m : ℕ} : n * m = 0 → n = 0 ∨ m = 0 :=
  match n with
  | zero => λ _ => Or.inl rfl
  | successor n =>
    λ h =>
    have h₁ : (n * m) + m = 0 := (successor_multiply n m).symm.trans h
    have h₂ : (n * m) = 0 ∧ m = 0 := equal_zero_of_add_equal_zero h₁
    Or.inr h₂.right

theorem multiply_equal_zero_of_equal_zero {n m : ℕ} : n = 0 ∨ m = 0 → n * m = 0 := by
  intro h
  cases h with
  | inl n_equal_zero => calc
    n * m = 0 * m := congrArg (. * m) n_equal_zero
    _     = 0     := zero_multiply m
  | inr m_equal_zero => calc
    n * m = n * 0 := congrArg (n * .) m_equal_zero
    _     = 0     := multiply_zero n

theorem positive_of_multiply_positive {n m : ℕ} (h : n * m ≠ 0) : n ≠ 0 ∧ m ≠ 0 :=
  have : ¬(n = 0 ∨ m = 0) := mt multiply_equal_zero_of_equal_zero h
  not_or.mp this

theorem multiply_positive_of_positive {n m : ℕ} (hn : n ≠ 0) (hm : m ≠ 0) : n * m ≠ 0 :=
  have : ¬(n = 0 ∨ m = 0) := not_or.mpr (And.intro hn hm)
  mt equal_zero_of_multiply_equal_zero this

theorem multiply_left_commutative (n m k : ℕ) : n * (m * k) = m * (n * k) := by
  rw [← multiply_associative, multiply_commutative n m, multiply_associative]

theorem multiply_right_commutative (n m k : ℕ) : (n * m) * k = (n * k) * m := by
  rw [multiply_associative, multiply_commutative m k, ← multiply_associative]
#+end_src

Finally, we show that multiplication by a nonzero natural number
respects the order relation, and use this to prove the cancellation
law for multiplication.

#+begin_src lean4
theorem multiply_left_less_than {m k : ℕ} (h_less_than : m < k) (n : ℕ) (hn_positive : n ≠ 0) : n * m < n * k := by
  let ⟨a, ⟨(ha_positive : a ≠ 0), (h_exists : m + a = k)⟩⟩ := equal_add_positive_of_less_than h_less_than
  apply less_than_of_equal_add_positive
  . show n * a ≠ 0
    exact multiply_positive_of_positive hn_positive ha_positive
  . calc
    n * m + n * a = n * (m + a) := (left_distributive n m a).symm
    _             = n * k       := congrArg (n * .) h_exists

theorem multiply_left_cancel {n m k : ℕ} (h_equal : n * m = n * k) (h_positive : n ≠ 0) : m = k :=
  match less_than_trichotomous m k with
  | Or.inl h_less_than =>
    have : n * m ≠ n * k := not_equal_of_less_than (multiply_left_less_than h_less_than n h_positive)
    absurd h_equal this
  | Or.inr (Or.inl h_equal) => h_equal
  | Or.inr (Or.inr h_greater_than) =>
    have : n * k ≠ n * m := not_equal_of_less_than (multiply_left_less_than h_greater_than n h_positive)
    absurd h_equal this.symm

theorem multiply_right_cancel {n m k : ℕ} (h_equal : n * k = m * k) (h_positive : k ≠ 0) : n = m :=
  have := calc
    k * n = n * k := multiply_commutative k n
    _     = m * k := h_equal
    _     = k * m := multiply_commutative m k
  multiply_left_cancel this h_positive

#+end_src

*** Division algorithm and exponentiation

This just a stub for now, I would like to rewrite ~quotient_remainder~
into a type-level algorithm using subtypes and rename it to ~divideWithRemainder~.

#+begin_src lean4
theorem quotient_remainder {n q : ℕ} (q_positive : q ≠ 0) :
  ∃ (p : ℕ × ℕ),
  let ⟨m, r⟩ := p; n = m * q + r ∧ r < q := by
  induction n with
  | zero =>
    apply Exists.intro ⟨0, 0⟩
    apply And.intro
    . calc
      0 = 0 * q := (zero_multiply q).symm
      _ = (0 * q) + 0 := (add_zero (0 * q)).symm
    . have h_exists : 0 + q = q := zero_add q
      exact less_than_of_equal_add_positive q_positive h_exists
  | successor n ih =>
    let ⟨⟨m, r⟩, ⟨(h_exists : n = m * q + r), (h_less_than : r < q)⟩⟩ := ih
    show ∃ p, let ⟨m, r⟩ := p; successor n = m * q + r ∧ r < q
    have : successor r = q ∨ successor r < q := 
      (Or.commutative.mp ∘ less_than_or_equal_of_less_equal ∘ successor_less_equal_of_less_than) h_less_than
    cases this with
    | inl h_equal => 
      apply Exists.intro ⟨successor m, 0⟩
      apply And.intro
      . calc
          successor n = successor (m * q + r)         := congrArg successor h_exists
          _           = m * q + successor r           := (add_successor (m * q) r).symm
          _           = m * successor r + successor r := congrArg (m * . + successor r) h_equal.symm
          _           = successor m * successor r     := (successor_multiply m (successor r)).symm
          _           = successor m * q               := congrArg (successor m * .) h_equal
          _           = successor m * q + 0           := (add_zero (successor m * q)).symm
      . exact zero_less_than_positive q_positive
    | inr h_less_than =>
      apply Exists.intro ⟨m, successor r⟩
      apply And.intro
      . calc
          successor n = successor (m * q + r) := congrArg successor h_exists
          _ = m * q + successor r := (add_successor (m * q) r).symm
      . exact h_less_than
#+end_src

#+begin_src lean4
def power (m : ℕ) : ℕ → ℕ
| 0 => 1
| successor n => (power m n) * m

instance : Pow Natural Natural where
  pow := power
#+end_src

** Integer
** Rational
** Utilities
*** Function
*** Logic
*** Order
*** Quotient
*** Syntax
